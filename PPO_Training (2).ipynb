{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752096f1-6915-489a-bbef-ac48ab80f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trl in /home/azureuser/.local/lib/python3.10/site-packages (0.7.11)\n",
      "Requirement already satisfied: accelerate in /home/azureuser/.local/lib/python3.10/site-packages (from trl) (0.28.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/azureuser/.local/lib/python3.10/site-packages (from trl) (4.37.2)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/azureuser/.local/lib/python3.10/site-packages (from trl) (2.1.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/azureuser/.local/lib/python3.10/site-packages (from trl) (0.5.11)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/azureuser/.local/lib/python3.10/site-packages (from trl) (1.26.1)\n",
      "Requirement already satisfied: datasets in /home/azureuser/.local/lib/python3.10/site-packages (from trl) (2.16.1)\n",
      "Requirement already satisfied: networkx in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: sympy in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.18.1)\n",
      "Requirement already satisfied: filelock in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.1.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/azureuser/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.3.52)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (23.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.31.0->trl) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/azureuser/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/azureuser/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.6.4)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/azureuser/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/azureuser/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.6.0)\n",
      "Requirement already satisfied: psutil in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate->trl) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (13.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (0.70.15)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: aiohttp in /home/azureuser/.local/lib/python3.10/site-packages (from datasets->trl) (3.8.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (3.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/azureuser/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers>=4.31.0->trl) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azureuser/.local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers>=4.31.0->trl) (1.26.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/azureuser/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/azureuser/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/azureuser/.local/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/azureuser/.local/lib/python3.10/site-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/azureuser/.local/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets->trl) (2022.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/azureuser/.local/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/azureuser/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/azureuser/.local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: psutil in /home/azureuser/.local/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: typing-extensions in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.0)\n",
      "Requirement already satisfied: jinja2 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: networkx in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/azureuser/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/azureuser/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in /home/azureuser/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/azureuser/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/azureuser/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azureuser/.local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/azureuser/.local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/azureuser/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install trl\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c530592a-e985-42a0-ba77-84942f4023df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, BitsAndBytesConfig,AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from trl import RewardTrainer, SFTTrainer , AutoModelForSeq2SeqLMWithValueHead,PPOTrainer, PPOConfig\n",
    "from trl.core import LengthSampler\n",
    "from trl import create_reference_model\n",
    "from datasets import Dataset, load_dataset\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a61b2b-0739-44ce-8e7c-c9c9c05fa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba8019f-f0ce-45ba-b976-c00cb7b1156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('CarperAI/openai_summarize_tldr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec68d7f-9344-4be3-a397-67e59d26d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea20565f-12c9-4915-bb8d-50c9c8e5b42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'label'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840c5238-df53-474e-b17b-3d7a050d3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"label\", \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9cf91f-fcf0-4e63-8b5e-41651bb1c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0604e0d-3f4f-417c-8e42-6b5730fa82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### If we would have trained the 1st step(SFT), then that model will come here.\n",
    "\n",
    "policy_model_id = \"pszemraj/led-base-book-summary\"\n",
    "policy_model = AutoModelForSeq2SeqLM.from_pretrained(policy_model_id)\n",
    "policy_model.to(device)\n",
    "policy_tokenizer = AutoTokenizer.from_pretrained(policy_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0406866-49d9-47c3-ab1b-b4f63dc97a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoModelForSeq2SeqLMWithValueHead(\n",
       "  (pretrained_model): LEDForConditionalGeneration(\n",
       "    (led): LEDModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): LEDEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LEDLearnedPositionalEmbedding(16384, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x LEDEncoderLayer(\n",
       "            (self_attn): LEDEncoderAttention(\n",
       "              (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): LEDDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LEDLearnedPositionalEmbedding(1024, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x LEDDecoderLayer(\n",
       "            (self_attn): LEDDecoderAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): LEDDecoderAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(policy_model_id) \n",
    "ppo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92795ae1-0a36-4378-a7f7-6dabd829b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(policy_model_id) \n",
    "# ref_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e68d2d50-a76b-4e3c-af4e-2edfc7d9f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model_directory = \"reward_model\"\n",
    "reward_tokenizer_directory = \"reward_model_tokenizer\"\n",
    "\n",
    "rm_model = AutoModelForSequenceClassification.from_pretrained(reward_model_directory).to(device)\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(reward_tokenizer_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b8bbe9-2efb-4e40-b851-92fe62c8ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8  # 80% for training, 20% for evaluation\n",
    "num_train_samples = int(split_ratio * len(dataset))\n",
    "train_dataset = dataset.select(range(num_train_samples))\n",
    "eval_dataset = dataset.select(range(num_train_samples, len(dataset)))\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    # Tokenize the prompt and store it as input_ids. Also return the response.\n",
    "    return {\n",
    "        \"input_ids\": policy_tokenizer(example[\"prompt\"], return_tensors=\"pt\", truncation=True, max_length=512)[\"input_ids\"].squeeze(),\n",
    "        \"response\": example[\"response\"],\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=False)\n",
    "eval_dataset = eval_dataset.map(tokenize_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89ab372b-126b-40fd-96e1-4be7482214db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['prompt', 'response', 'input_ids'],\n",
       "     num_rows: 800\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'response', 'input_ids'],\n",
       "     num_rows: 200\n",
       " }))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d037bb18-0eae-41be-8bc3-707508048f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"SUBREDDIT: r/relationships\\nTITLE: I (f/22) have to figure out if I want to still know these girls or not and would hate to sound insulting\\nPOST: Not sure if this belongs here but it's worth a try. \\n\\nBackstory:\\nWhen I (f/22) went through my first real breakup 2 years ago because he needed space after a year of dating roand  it effected me more than I thought. It was a horrible time in my life due to living with my mother and finally having the chance to cut her out of my life. I can admit because of it was an emotional wreck and this guy was stable and didn't know how to deal with me. We ended by him avoiding for a month or so after going to a festival with my friends. When I think back I wish he just ended. So after he ended it added my depression I suffered but my friends helped me through it and I got rid of everything from him along with cutting contact. \\n\\nNow: Its been almost 3 years now and I've gotten better after counselling and mild anti depressants. My mother has been out of my life since then so there's been alot of progress. Being stronger after learning some lessons there been more insight about that time of my life but when I see him or a picture everything comes back. The emotions and memories bring me back down. \\n\\nHis friends (both girls) are on my facebook because we get along well which is hard to find and I know they'll always have his back. But seeing him in a picture or talking to him at a convention having a conversation is tough. Crying confront of my current boyfriend is something I want to avoid. \\n\\nSo I've been thinking that I have to cut contact with these girls because it's time to move on because it's healthier. It's best to avoid him as well. But will they be insulted? Will they accept it? Is there going to be awkwardness? I'm not sure if it's the right to do and could use some outside opinions.\\nTL;DR: \",\n",
       " 'response': \"I still have contact with an old ex's friends but can't stand to see or talk to him. His friends are really nice ,so how do I tell them I possibly want to unfriend them on Facebook because of him?\",\n",
       " 'input_ids': [0,\n",
       "  104,\n",
       "  12027,\n",
       "  36015,\n",
       "  45509,\n",
       "  35,\n",
       "  910,\n",
       "  73,\n",
       "  36275,\n",
       "  7903,\n",
       "  50118,\n",
       "  47217,\n",
       "  3850,\n",
       "  35,\n",
       "  38,\n",
       "  36,\n",
       "  506,\n",
       "  73,\n",
       "  2036,\n",
       "  43,\n",
       "  33,\n",
       "  7,\n",
       "  1955,\n",
       "  66,\n",
       "  114,\n",
       "  38,\n",
       "  236,\n",
       "  7,\n",
       "  202,\n",
       "  216,\n",
       "  209,\n",
       "  1972,\n",
       "  50,\n",
       "  45,\n",
       "  8,\n",
       "  74,\n",
       "  4157,\n",
       "  7,\n",
       "  2369,\n",
       "  22602,\n",
       "  50118,\n",
       "  47060,\n",
       "  35,\n",
       "  1491,\n",
       "  686,\n",
       "  114,\n",
       "  42,\n",
       "  12918,\n",
       "  259,\n",
       "  53,\n",
       "  24,\n",
       "  18,\n",
       "  966,\n",
       "  10,\n",
       "  860,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  19085,\n",
       "  6462,\n",
       "  35,\n",
       "  50118,\n",
       "  1779,\n",
       "  38,\n",
       "  36,\n",
       "  506,\n",
       "  73,\n",
       "  2036,\n",
       "  43,\n",
       "  439,\n",
       "  149,\n",
       "  127,\n",
       "  78,\n",
       "  588,\n",
       "  21310,\n",
       "  132,\n",
       "  107,\n",
       "  536,\n",
       "  142,\n",
       "  37,\n",
       "  956,\n",
       "  980,\n",
       "  71,\n",
       "  10,\n",
       "  76,\n",
       "  9,\n",
       "  4927,\n",
       "  4533,\n",
       "  463,\n",
       "  1437,\n",
       "  24,\n",
       "  36689,\n",
       "  162,\n",
       "  55,\n",
       "  87,\n",
       "  38,\n",
       "  802,\n",
       "  4,\n",
       "  85,\n",
       "  21,\n",
       "  10,\n",
       "  11385,\n",
       "  86,\n",
       "  11,\n",
       "  127,\n",
       "  301,\n",
       "  528,\n",
       "  7,\n",
       "  1207,\n",
       "  19,\n",
       "  127,\n",
       "  985,\n",
       "  8,\n",
       "  1747,\n",
       "  519,\n",
       "  5,\n",
       "  778,\n",
       "  7,\n",
       "  847,\n",
       "  69,\n",
       "  66,\n",
       "  9,\n",
       "  127,\n",
       "  301,\n",
       "  4,\n",
       "  38,\n",
       "  64,\n",
       "  8109,\n",
       "  142,\n",
       "  9,\n",
       "  24,\n",
       "  21,\n",
       "  41,\n",
       "  3722,\n",
       "  15107,\n",
       "  8,\n",
       "  42,\n",
       "  2173,\n",
       "  21,\n",
       "  4375,\n",
       "  8,\n",
       "  399,\n",
       "  75,\n",
       "  216,\n",
       "  141,\n",
       "  7,\n",
       "  432,\n",
       "  19,\n",
       "  162,\n",
       "  4,\n",
       "  166,\n",
       "  1249,\n",
       "  30,\n",
       "  123,\n",
       "  11473,\n",
       "  13,\n",
       "  10,\n",
       "  353,\n",
       "  50,\n",
       "  98,\n",
       "  71,\n",
       "  164,\n",
       "  7,\n",
       "  10,\n",
       "  3241,\n",
       "  19,\n",
       "  127,\n",
       "  964,\n",
       "  4,\n",
       "  520,\n",
       "  38,\n",
       "  206,\n",
       "  124,\n",
       "  38,\n",
       "  2813,\n",
       "  37,\n",
       "  95,\n",
       "  1249,\n",
       "  4,\n",
       "  407,\n",
       "  71,\n",
       "  37,\n",
       "  1249,\n",
       "  24,\n",
       "  355,\n",
       "  127,\n",
       "  6943,\n",
       "  38,\n",
       "  2152,\n",
       "  53,\n",
       "  127,\n",
       "  964,\n",
       "  1147,\n",
       "  162,\n",
       "  149,\n",
       "  24,\n",
       "  8,\n",
       "  38,\n",
       "  300,\n",
       "  7495,\n",
       "  9,\n",
       "  960,\n",
       "  31,\n",
       "  123,\n",
       "  552,\n",
       "  19,\n",
       "  3931,\n",
       "  1511,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  5975,\n",
       "  35,\n",
       "  3139,\n",
       "  57,\n",
       "  818,\n",
       "  155,\n",
       "  107,\n",
       "  122,\n",
       "  8,\n",
       "  38,\n",
       "  348,\n",
       "  5335,\n",
       "  357,\n",
       "  71,\n",
       "  24588,\n",
       "  8,\n",
       "  10439,\n",
       "  1475,\n",
       "  37018,\n",
       "  3277,\n",
       "  4,\n",
       "  1308,\n",
       "  985,\n",
       "  34,\n",
       "  57,\n",
       "  66,\n",
       "  9,\n",
       "  127,\n",
       "  301,\n",
       "  187,\n",
       "  172,\n",
       "  98,\n",
       "  89,\n",
       "  18,\n",
       "  57,\n",
       "  47375,\n",
       "  9,\n",
       "  2017,\n",
       "  4,\n",
       "  8374,\n",
       "  3651,\n",
       "  71,\n",
       "  2239,\n",
       "  103,\n",
       "  7079,\n",
       "  89,\n",
       "  57,\n",
       "  55,\n",
       "  8339,\n",
       "  59,\n",
       "  14,\n",
       "  86,\n",
       "  9,\n",
       "  127,\n",
       "  301,\n",
       "  53,\n",
       "  77,\n",
       "  38,\n",
       "  192,\n",
       "  123,\n",
       "  50,\n",
       "  10,\n",
       "  2170,\n",
       "  960,\n",
       "  606,\n",
       "  124,\n",
       "  4,\n",
       "  20,\n",
       "  8597,\n",
       "  8,\n",
       "  6180,\n",
       "  836,\n",
       "  162,\n",
       "  124,\n",
       "  159,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  9962,\n",
       "  964,\n",
       "  36,\n",
       "  17143,\n",
       "  1972,\n",
       "  43,\n",
       "  32,\n",
       "  15,\n",
       "  127,\n",
       "  10660,\n",
       "  142,\n",
       "  52,\n",
       "  120,\n",
       "  552,\n",
       "  157,\n",
       "  61,\n",
       "  16,\n",
       "  543,\n",
       "  7,\n",
       "  465,\n",
       "  8,\n",
       "  38,\n",
       "  216,\n",
       "  51,\n",
       "  581,\n",
       "  460,\n",
       "  33,\n",
       "  39,\n",
       "  124,\n",
       "  4,\n",
       "  125,\n",
       "  1782,\n",
       "  123,\n",
       "  11,\n",
       "  10,\n",
       "  2170,\n",
       "  50,\n",
       "  1686,\n",
       "  7,\n",
       "  123,\n",
       "  23,\n",
       "  10,\n",
       "  8825,\n",
       "  519,\n",
       "  10,\n",
       "  1607,\n",
       "  16,\n",
       "  1828,\n",
       "  4,\n",
       "  19803,\n",
       "  154,\n",
       "  10749,\n",
       "  9,\n",
       "  127,\n",
       "  595,\n",
       "  6578,\n",
       "  16,\n",
       "  402,\n",
       "  38,\n",
       "  236,\n",
       "  7,\n",
       "  1877,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  2847,\n",
       "  38,\n",
       "  348,\n",
       "  57,\n",
       "  2053,\n",
       "  14,\n",
       "  38,\n",
       "  33,\n",
       "  7,\n",
       "  847,\n",
       "  1511,\n",
       "  19,\n",
       "  209,\n",
       "  1972,\n",
       "  142,\n",
       "  24,\n",
       "  18,\n",
       "  86,\n",
       "  7,\n",
       "  517,\n",
       "  15,\n",
       "  142,\n",
       "  24,\n",
       "  18,\n",
       "  12732,\n",
       "  4,\n",
       "  85,\n",
       "  18,\n",
       "  275,\n",
       "  7,\n",
       "  1877,\n",
       "  123,\n",
       "  25,\n",
       "  157,\n",
       "  4,\n",
       "  125,\n",
       "  40,\n",
       "  51,\n",
       "  28,\n",
       "  32149,\n",
       "  116,\n",
       "  2290,\n",
       "  51,\n",
       "  3264,\n",
       "  24,\n",
       "  116,\n",
       "  1534,\n",
       "  89,\n",
       "  164,\n",
       "  7,\n",
       "  28,\n",
       "  11789,\n",
       "  1825,\n",
       "  116,\n",
       "  38,\n",
       "  437,\n",
       "  45,\n",
       "  686,\n",
       "  114,\n",
       "  24,\n",
       "  18,\n",
       "  5,\n",
       "  235,\n",
       "  7,\n",
       "  109,\n",
       "  8,\n",
       "  115,\n",
       "  304,\n",
       "  103,\n",
       "  751,\n",
       "  5086,\n",
       "  4,\n",
       "  50118,\n",
       "  22290,\n",
       "  131,\n",
       "  10644,\n",
       "  35,\n",
       "  1437,\n",
       "  2]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad80fe9c-a2e3-4b9c-8a27-75823e41b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f4e25c-bb04-4454-8f92-0e1403114dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prompt', 'response', 'input_ids'])\n"
     ]
    }
   ],
   "source": [
    "# Lets sample what the collator generates:\n",
    "sample_data = [train_dataset[i] for i in range(3)]  # take first three examples\n",
    "collated_data = collator(sample_data)\n",
    "print(collated_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e43ae67-00c3-436d-8628-087f1f9d4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=3\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "DEFAULT_REJECTED_SUMMARY_TEXT = \"This is a bad summary\"\n",
    "\n",
    "# Some initial values\n",
    "output_min_length = 30\n",
    "output_max_length = 150\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"temperature\": 1.0,\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "max_ppo_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4b98914-3ae3-4287-bb1c-24ae60c83a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=policy_model_id,\n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5945fad3-e0dc-4114-a31f-e6f52ba5cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(config=config,\n",
    "                         model=ppo_model,\n",
    "                         #ref_model=ref_model,\n",
    "                         tokenizer=policy_tokenizer,\n",
    "                         dataset=train_dataset,\n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d32659f9-5ffc-4a27-8bdc-93aac6e9d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def score_summaries(model, tokenizer, chosen_summary, rejected_summary):\n",
    "    # Tokenize the inputs\n",
    "    chosen_tokens = tokenizer(chosen_summary, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "    rejected_tokens = tokenizer(rejected_summary, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "    chosen_tokens.to(device)\n",
    "    rejected_tokens.to(device)\n",
    "\n",
    "    # Get logits from the model\n",
    "    with torch.no_grad():\n",
    "        chosen_logits = model(**chosen_tokens).logits\n",
    "        rejected_logits = model(**rejected_tokens).logits\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    chosen_probs = F.softmax(chosen_logits, dim=-1)\n",
    "    rejected_probs = F.softmax(rejected_logits, dim=-1)\n",
    "\n",
    "    # Assuming the positive class (indicating 'chosen' is good) is the second one\n",
    "    chosen_score = chosen_probs[0][1].item()\n",
    "    rejected_score = rejected_probs[0][1].item()\n",
    "\n",
    "    # Extract logits for each summary\n",
    "    chosen_logit = chosen_logits[0][1].item()\n",
    "    rejected_logit = rejected_logits[0][1].item()\n",
    "\n",
    "    return chosen_score, rejected_score, chosen_logit, rejected_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c51f9886-d0ee-47be-97c2-98a649487939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Score: 0.5161\n",
      "Rejected Score: 0.4526\n",
      "Chosen Logit: 0.3487\n",
      "Rejected Logit: 0.0255\n"
     ]
    }
   ],
   "source": [
    "chosen_summary = \"Water meter in another condo is not in our condo. What can we do legally to restore water to my condo complex?\"\n",
    "rejected_summary = \"Go fix the problem.\"\n",
    "\n",
    "chosen_score, rejected_score, chosen_logit, rejected_logit = score_summaries(rm_model, rm_tokenizer, chosen_summary, rejected_summary)\n",
    "\n",
    "print(f\"Chosen Score: {chosen_score:.4f}\")\n",
    "print(f\"Rejected Score: {rejected_score:.4f}\")\n",
    "\n",
    "print(f\"Chosen Logit: {chosen_logit:.4f}\")\n",
    "print(f\"Rejected Logit: {rejected_logit:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e802ce4-dc9b-4167-8eb2-90f07ad0d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_55439/3451821770.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prompt_tensor = torch.tensor(prompt_tensor).to(device)\n",
      "Input ids are automatically padded from 493 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 431 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 195 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 221 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 274 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 450 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 504 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 293 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 289 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 361 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 326 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 401 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 363 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 212 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 511 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 266 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "1it [00:32, 32.72s/it]Input ids are automatically padded from 369 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -9.676851732365321e-06\n",
      "ppo/returns/mean: 0.5275627374649048\n",
      "ppo/policy/advantages_mean: -0.002801092341542244\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 491 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 339 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 294 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 403 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 227 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 351 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 456 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 490 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 301 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 207 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 474 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 219 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 478 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (95.64) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (30.93) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (148.18) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (17.95) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -6.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2it [01:04, 32.06s/it]Input ids are automatically padded from 285 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -6.1851701736450195\n",
      "ppo/returns/mean: 0.8105399012565613\n",
      "ppo/policy/advantages_mean: 0.00224125268869102\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 342 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 355 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 429 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 284 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 236 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 332 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 381 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 283 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 336 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 179 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 411 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 211 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 392 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 484 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (147.26) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (24.95) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (10296.73) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (19.20) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (31.10) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (38.73) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -27.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "3it [01:35, 31.83s/it]Input ids are automatically padded from 282 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -27.92009162902832\n",
      "ppo/returns/mean: 1.771461844444275\n",
      "ppo/policy/advantages_mean: -0.004473959561437368\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 391 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 404 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 437 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 482 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 367 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 258 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 253 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 472 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 297 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 417 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 435 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 464 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 244 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 324 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "4it [02:07, 31.91s/it]Input ids are automatically padded from 448 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.988086700439453\n",
      "ppo/returns/mean: 0.05924704670906067\n",
      "ppo/policy/advantages_mean: 0.017941389232873917\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 333 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 252 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 463 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 299 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 188 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 459 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 292 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 263 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 226 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 500 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 315 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 314 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 272 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "5it [02:39, 31.79s/it]Input ids are automatically padded from 483 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.295307159423828\n",
      "ppo/returns/mean: -0.39417099952697754\n",
      "ppo/policy/advantages_mean: 0.007847161963582039\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 462 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 337 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 214 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 286 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 345 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 393 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 379 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 470 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 233 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 498 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 380 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 208 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "6it [03:11, 31.83s/it]Input ids are automatically padded from 396 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.55228614807129\n",
      "ppo/returns/mean: -0.5506460666656494\n",
      "ppo/policy/advantages_mean: 0.026833228766918182\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 414 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 384 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 335 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 245 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 269 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 205 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 230 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 446 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 267 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 356 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 322 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 218 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "7it [03:42, 31.74s/it]Input ids are automatically padded from 308 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.767576217651367\n",
      "ppo/returns/mean: -0.5003163814544678\n",
      "ppo/policy/advantages_mean: 0.013013686053454876\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 317 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 376 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 277 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 509 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 402 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 412 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 358 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 397 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "8it [04:14, 31.57s/it]Input ids are automatically padded from 400 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.166448593139648\n",
      "ppo/returns/mean: -0.6423916220664978\n",
      "ppo/policy/advantages_mean: 0.016633620485663414\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 360 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 183 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 295 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 371 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 375 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 385 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "9it [04:46, 31.96s/it]Input ids are automatically padded from 453 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.087535858154297\n",
      "ppo/returns/mean: -1.0688539743423462\n",
      "ppo/policy/advantages_mean: 0.012802040204405785\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 160 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 231 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 405 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 304 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 232 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 352 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 264 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 423 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 62 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 168 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 492 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (10.46) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (16.48) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "10it [05:21, 32.64s/it]Input ids are automatically padded from 374 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.673182487487793\n",
      "ppo/returns/mean: -1.175992727279663\n",
      "ppo/policy/advantages_mean: 0.013759779743850231\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 422 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 407 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 409 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 280 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 305 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 234 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 445 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 235 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "11it [05:55, 33.04s/it]Input ids are automatically padded from 408 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.181324005126953\n",
      "ppo/returns/mean: -1.4192225933074951\n",
      "ppo/policy/advantages_mean: 0.006254791282117367\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 191 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 420 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 350 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 467 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 486 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 460 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 479 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 193 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 421 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 331 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "12it [06:27, 32.93s/it]Input ids are automatically padded from 438 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.493758201599121\n",
      "ppo/returns/mean: -1.210973858833313\n",
      "ppo/policy/advantages_mean: 0.015035843476653099\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 387 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 480 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 228 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 158 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 291 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 278 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 512 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 465 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 349 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 307 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 499 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 225 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (18.28) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (15.58) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "13it [07:00, 32.76s/it]Input ids are automatically padded from 455 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.579954147338867\n",
      "ppo/returns/mean: -1.3494033813476562\n",
      "ppo/policy/advantages_mean: 0.009626551531255245\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 239 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 265 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 242 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 353 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 343 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 288 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 260 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "14it [07:33, 33.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.250015258789062\n",
      "ppo/returns/mean: -1.399639368057251\n",
      "ppo/policy/advantages_mean: 0.007492770440876484\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 508 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 354 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 475 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 357 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 377 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 298 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 348 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 196 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "15it [08:05, 32.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.326959609985352\n",
      "ppo/returns/mean: -1.4371449947357178\n",
      "ppo/policy/advantages_mean: 0.024734018370509148\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 255 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 273 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 487 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 425 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 406 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 505 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "16it [08:35, 31.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.720958709716797\n",
      "ppo/returns/mean: -1.2684223651885986\n",
      "ppo/policy/advantages_mean: 0.022238291800022125\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 312 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 378 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 394 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 416 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 271 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 366 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 419 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 275 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "17it [09:07, 31.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.602121353149414\n",
      "ppo/returns/mean: -1.449101448059082\n",
      "ppo/policy/advantages_mean: 0.006214344408363104\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 173 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 362 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 259 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 185 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 327 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 203 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 489 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "18it [09:36, 31.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 14.448728561401367\n",
      "ppo/returns/mean: -1.398282766342163\n",
      "ppo/policy/advantages_mean: 0.020223623141646385\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 318 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 497 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 184 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 469 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 340 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 270 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (12.65) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (385.04) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "19it [10:04, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.194849014282227\n",
      "ppo/returns/mean: -1.447683334350586\n",
      "ppo/policy/advantages_mean: 0.003445131704211235\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 197 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 261 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 194 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 390 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 241 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 306 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 432 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 346 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "20it [10:36, 30.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.154577255249023\n",
      "ppo/returns/mean: -1.2357490062713623\n",
      "ppo/policy/advantages_mean: -0.03138148784637451\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 171 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 458 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 257 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 426 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 319 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (14.54) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/azureuser/.local/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1212: UserWarning: The average ratio of batch (24.63) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "21it [11:03, 29.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.178276062011719\n",
      "ppo/returns/mean: -1.3342101573944092\n",
      "ppo/policy/advantages_mean: 0.0051803006790578365\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 325 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 296 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 310 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 169 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 249 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 359 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 247 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 330 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "22it [11:29, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.931812286376953\n",
      "ppo/returns/mean: -1.4793275594711304\n",
      "ppo/policy/advantages_mean: -0.03212476521730423\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 251 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 373 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 215 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 186 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 444 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "23it [11:55, 27.77s/it]Input ids are automatically padded from 189 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.41216278076172\n",
      "ppo/returns/mean: -1.4293303489685059\n",
      "ppo/policy/advantages_mean: -0.02179853245615959\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 302 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 395 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 389 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 503 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 386 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 300 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "24it [12:21, 27.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.313270568847656\n",
      "ppo/returns/mean: -1.3590707778930664\n",
      "ppo/policy/advantages_mean: 0.04553950950503349\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 181 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 501 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 452 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 334 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 428 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 311 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "25it [12:45, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.455368041992188\n",
      "ppo/returns/mean: -1.4842860698699951\n",
      "ppo/policy/advantages_mean: 0.015880003571510315\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 398 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 502 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 372 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 507 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 192 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 321 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "26it [13:11, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.37262725830078\n",
      "ppo/returns/mean: -1.3334407806396484\n",
      "ppo/policy/advantages_mean: 0.03635761886835098\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 476 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 209 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 279 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "27it [13:34, 25.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.29381561279297\n",
      "ppo/returns/mean: -1.3798103332519531\n",
      "ppo/policy/advantages_mean: 0.01042242906987667\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 370 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 329 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 237 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "28it [13:57, 24.46s/it]Input ids are automatically padded from 172 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.86618423461914\n",
      "ppo/returns/mean: -1.6342324018478394\n",
      "ppo/policy/advantages_mean: 0.01997721567749977\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 481 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 488 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 238 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 223 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "29it [14:20, 24.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.899490356445312\n",
      "ppo/returns/mean: -2.017723798751831\n",
      "ppo/policy/advantages_mean: 0.030627649277448654\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 382 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 418 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 485 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 468 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 434 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 415 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 303 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "30it [14:43, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.28044891357422\n",
      "ppo/returns/mean: -1.9173072576522827\n",
      "ppo/policy/advantages_mean: 0.003466537222266197\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 506 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 441 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 383 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "31it [15:06, 23.52s/it]Input ids are automatically padded from 248 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 22.62061309814453\n",
      "ppo/returns/mean: -1.8724308013916016\n",
      "ppo/policy/advantages_mean: -0.016265610232949257\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 243 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 43 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "32it [15:29, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.71583366394043\n",
      "ppo/returns/mean: -1.9044256210327148\n",
      "ppo/policy/advantages_mean: 0.042788416147232056\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 287 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 477 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 206 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 443 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 167 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "33it [15:52, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.647018432617188\n",
      "ppo/returns/mean: -2.075765371322632\n",
      "ppo/policy/advantages_mean: 0.0029725029598921537\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 316 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 182 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 200 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "34it [16:14, 22.91s/it]Input ids are automatically padded from 430 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.32471466064453\n",
      "ppo/returns/mean: -1.8260258436203003\n",
      "ppo/policy/advantages_mean: -0.007469045929610729\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [16:36, 22.70s/it]Input ids are automatically padded from 202 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.99820327758789\n",
      "ppo/returns/mean: -1.9017455577850342\n",
      "ppo/policy/advantages_mean: 0.018114252015948296\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 457 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 187 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 217 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 510 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "36it [16:59, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 24.015426635742188\n",
      "ppo/returns/mean: -2.2660670280456543\n",
      "ppo/policy/advantages_mean: 0.03504979610443115\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 471 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 222 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "37it [17:21, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.361228942871094\n",
      "ppo/returns/mean: -1.6828737258911133\n",
      "ppo/policy/advantages_mean: 0.027435656636953354\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 157 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 413 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 313 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "38it [17:43, 22.43s/it]Input ids are automatically padded from 473 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.096630096435547\n",
      "ppo/returns/mean: -1.6212701797485352\n",
      "ppo/policy/advantages_mean: 0.0009362204000353813\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 262 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 178 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 91 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "39it [18:05, 22.17s/it]Input ids are automatically padded from 174 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 494 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.9088134765625\n",
      "ppo/returns/mean: -1.7448195219039917\n",
      "ppo/policy/advantages_mean: -0.0009860291611403227\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 410 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 320 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "40it [18:27, 22.11s/it]Input ids are automatically padded from 216 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.28685188293457\n",
      "ppo/returns/mean: -1.5581252574920654\n",
      "ppo/policy/advantages_mean: 0.010299380868673325\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 220 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 439 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "41it [18:49, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.75981903076172\n",
      "ppo/returns/mean: -1.445212721824646\n",
      "ppo/policy/advantages_mean: 0.06496807187795639\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 290 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "42it [19:11, 22.01s/it]Input ids are automatically padded from 368 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.607620239257812\n",
      "ppo/returns/mean: -2.1378445625305176\n",
      "ppo/policy/advantages_mean: 0.008488010615110397\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 440 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 190 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 256 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 347 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 213 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "43it [19:32, 21.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.683544158935547\n",
      "ppo/returns/mean: -1.8872864246368408\n",
      "ppo/policy/advantages_mean: -0.021215610206127167\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 276 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "44it [19:54, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.072036743164062\n",
      "ppo/returns/mean: -1.848901629447937\n",
      "ppo/policy/advantages_mean: -0.012770958244800568\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 436 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 254 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "45it [20:17, 22.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.51968002319336\n",
      "ppo/returns/mean: -1.6432360410690308\n",
      "ppo/policy/advantages_mean: -0.0025103092193603516\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 341 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 199 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 210 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "46it [20:39, 22.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.947484970092773\n",
      "ppo/returns/mean: -1.4024991989135742\n",
      "ppo/policy/advantages_mean: -0.011554657481610775\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 323 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 246 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "47it [21:00, 21.97s/it]Input ids are automatically padded from 495 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.448421478271484\n",
      "ppo/returns/mean: -1.4475255012512207\n",
      "ppo/policy/advantages_mean: -0.07981672883033752\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 338 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 364 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 328 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "48it [21:22, 21.79s/it]Input ids are automatically padded from 204 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.476886749267578\n",
      "ppo/returns/mean: -1.948337435722351\n",
      "ppo/policy/advantages_mean: -0.007052720990031958\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [21:43, 21.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.28260612487793\n",
      "ppo/returns/mean: -1.769110083580017\n",
      "ppo/policy/advantages_mean: 0.024180859327316284\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 388 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "50it [22:05, 26.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.823970794677734\n",
      "ppo/returns/mean: -1.6166677474975586\n",
      "ppo/policy/advantages_mean: 0.027625955641269684\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if step >= max_ppo_steps: # Break when we reach max_steps.\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    if isinstance(prompt_tensors, list) and all(isinstance(item, list) for item in prompt_tensors): # HACK!!! Check if original_prompt_tensors is a list of lists\n",
    "        lengths = [len(seq) for seq in prompt_tensors] # Verify if sequences have fixed or variable length\n",
    "        unique_lengths = set(lengths)\n",
    "\n",
    "        if len(unique_lengths) > 1: # If sequences have variable lengths, pad them\n",
    "            max_length = max(unique_lengths)\n",
    "            original_prompt_tensors = [seq + [0] * (max_length - len(seq)) for seq in prompt_tensors]  # padding with zeros\n",
    "\n",
    "        prompt_tensors = [torch.tensor(seq).to(device) for seq in prompt_tensors] # Convert original_prompt_tensors to individual tensors\n",
    "\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        prompt_tensor = torch.tensor(prompt_tensor).to(device)\n",
    "        max_new_tokens = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    batch[\"response\"] = [policy_tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    chosen_summaries = batch[\"response\"]\n",
    "    rejected_summaries = [DEFAULT_REJECTED_SUMMARY_TEXT] * len(batch[\"response\"])\n",
    "\n",
    "    reward_tensors = []\n",
    "\n",
    "    for chosen_summary, rejected_summary in zip(chosen_summaries, rejected_summaries):\n",
    "        chosen_score, _, _, _ = score_summaries(rm_model, rm_tokenizer, chosen_summary, rejected_summary)\n",
    "        reward_tensors.append(torch.tensor(chosen_score))\n",
    "\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}') # Measures how different the policy's action distribution after the update is from the action distribution before the update. PPO tries to make these changes very small to avoid sudden changes.\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}') # This is the average return achieved by the agent. Higher is better.\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}') # Measures how much better an action is than the average action at a given state.\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b345a9-8501-45a1-9965-253e70b1db2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective/kl': 18.823970794677734,\n",
       " 'objective/kl_dist': array([24.216343, 19.108904, 21.07835 , 16.415909, 17.75911 , 14.864124,\n",
       "        26.851608, 22.932692, 16.316277, 13.655459, 23.952072, 15.781115,\n",
       "        18.548454, 11.432112, 10.116042, 28.154984], dtype=float32),\n",
       " 'objective/logprobs': array([[-1.25168972e-05, -1.44583166e+00, -8.41871321e-01,\n",
       "         -8.78231823e-01, -2.08248310e-02, -8.10619895e-06,\n",
       "         -2.79246407e+01, -1.77062149e+01, -1.73297615e+01,\n",
       "         -1.81244164e+01, -1.67996159e+01, -1.94089375e+01,\n",
       "         -1.90715580e+01, -1.70691032e+01, -1.64233971e+01,\n",
       "         -1.63964252e+01, -1.93038960e+01, -1.86627960e+01,\n",
       "         -1.83176861e+01, -1.76473846e+01, -1.81938953e+01,\n",
       "         -1.69870052e+01, -1.80033016e+01, -1.83171062e+01,\n",
       "         -1.73901234e+01, -1.84903088e+01],\n",
       "        [-1.33513513e-05, -1.82678267e-01, -1.44932792e-01,\n",
       "         -3.91438752e-02, -3.55180586e-04, -2.02771928e-03,\n",
       "         -2.76918132e-02, -2.46851967e-04, -2.89469872e+01,\n",
       "         -1.89911079e+01, -1.90506840e+01, -1.87851601e+01,\n",
       "         -1.92550488e+01, -1.78515244e+01, -1.66474533e+01,\n",
       "         -1.71731396e+01, -1.71186237e+01, -1.82537651e+01,\n",
       "         -1.88764744e+01, -1.89891644e+01, -1.89907551e+01,\n",
       "         -1.85750732e+01, -1.93306084e+01, -1.83131065e+01,\n",
       "         -1.74152317e+01, -1.84903221e+01],\n",
       "        [-2.45568117e-05, -1.61751842e+00, -1.41724002e+00,\n",
       "         -3.16446036e-01, -1.42487744e-02, -3.64773769e-05,\n",
       "         -2.50848866e+01, -1.69652824e+01, -1.65020885e+01,\n",
       "         -1.63687477e+01, -1.58577232e+01, -1.59894390e+01,\n",
       "         -1.67502632e+01, -1.59777546e+01, -1.57641754e+01,\n",
       "         -1.57435236e+01, -1.59057045e+01, -1.61487846e+01,\n",
       "         -1.59061279e+01, -1.56474113e+01, -1.59934130e+01,\n",
       "         -1.56188297e+01, -1.59240255e+01, -1.58735638e+01,\n",
       "         -1.54945755e+01, -1.57160015e+01],\n",
       "        [-1.26361047e-05, -6.25677586e-01, -2.91724414e-01,\n",
       "         -5.35225670e-04, -2.81236111e-03, -9.14293487e-05,\n",
       "         -9.87518812e-04, -1.99893999e-04, -8.59431177e-03,\n",
       "         -8.94065670e-06, -2.90310020e+01, -1.95499477e+01,\n",
       "         -1.99094372e+01, -1.72326317e+01, -1.65921040e+01,\n",
       "         -1.90115147e+01, -1.78508930e+01, -1.97084770e+01,\n",
       "         -1.59064112e+01, -1.65142670e+01, -1.91935329e+01,\n",
       "         -1.87841110e+01, -1.84700031e+01, -1.76644650e+01,\n",
       "         -1.57517309e+01, -1.59811182e+01],\n",
       "        [-1.46626353e-05, -1.56833753e-01, -7.85999417e-01,\n",
       "         -5.60763739e-02, -1.15398522e-02, -1.41133845e-04,\n",
       "         -3.97841446e-04, -9.53669769e-06, -1.69241184e-03,\n",
       "         -5.88260412e-01, -4.96740919e-04, -4.25165333e-02,\n",
       "         -1.87780522e-02, -1.71659904e-05, -2.91611881e+01,\n",
       "         -1.82228584e+01, -1.76624355e+01, -1.92042446e+01,\n",
       "         -1.94017372e+01, -1.82379036e+01, -1.91462746e+01,\n",
       "         -1.83205318e+01, -1.77614937e+01, -1.75244713e+01,\n",
       "         -1.78787766e+01, -1.88447819e+01],\n",
       "        [-2.20534748e-05, -4.91085976e-01, -1.96763873e-03,\n",
       "         -1.36401562e-03, -8.46051238e-03, -1.38151541e-03,\n",
       "         -4.70898720e-03, -6.18677077e-05, -2.95271416e+01,\n",
       "         -2.17209358e+01, -2.11395206e+01, -2.14680634e+01,\n",
       "         -1.88791199e+01, -2.10198727e+01, -1.89751816e+01,\n",
       "         -1.75421448e+01, -2.03471832e+01, -1.75727158e+01,\n",
       "         -2.05585041e+01, -1.94988613e+01, -2.00719509e+01,\n",
       "         -1.71384487e+01, -1.80779438e+01, -1.63403320e+01,\n",
       "         -1.89130325e+01, -1.88351212e+01],\n",
       "        [-2.56296680e-05, -8.96667615e-02, -8.54568183e-01,\n",
       "         -1.71648413e-02, -2.27109785e-03, -9.00101732e-04,\n",
       "         -1.80585761e-04, -2.35492717e-02, -1.61730841e-01,\n",
       "         -4.10274277e-03, -3.35451402e-02, -9.62985680e-04,\n",
       "         -1.70523413e-02, -2.05037868e-05, -2.89748383e+01,\n",
       "         -2.06340618e+01, -2.06194572e+01, -2.16591187e+01,\n",
       "         -2.24604874e+01, -1.97046356e+01, -2.18088036e+01,\n",
       "         -2.10338917e+01, -2.13035164e+01, -1.97789536e+01,\n",
       "         -1.97432785e+01, -2.05256424e+01],\n",
       "        [-9.53669769e-06, -7.94560134e-01, -8.93741906e-01,\n",
       "         -6.19342387e-01, -1.93151347e-02, -1.54971951e-06,\n",
       "         -2.77834034e+01, -1.73835793e+01, -1.69456062e+01,\n",
       "         -1.71806183e+01, -1.63030148e+01, -1.72377853e+01,\n",
       "         -1.75695229e+01, -1.62846699e+01, -1.60157547e+01,\n",
       "         -1.60654240e+01, -1.72229080e+01, -1.76592255e+01,\n",
       "         -1.75705757e+01, -1.65496731e+01, -1.68057060e+01,\n",
       "         -1.59256954e+01, -1.62308865e+01, -1.66750984e+01,\n",
       "         -1.65205917e+01, -1.72754936e+01],\n",
       "        [-1.35897662e-05, -1.20777721e-02, -5.46056390e-01,\n",
       "         -3.55508998e-02, -2.01582257e-03, -1.30546177e-02,\n",
       "         -2.74180979e-06, -2.97139111e+01, -1.83341713e+01,\n",
       "         -1.85139923e+01, -1.83936558e+01, -1.79569302e+01,\n",
       "         -2.02463779e+01, -1.91468010e+01, -1.76348286e+01,\n",
       "         -1.82689285e+01, -1.76685715e+01, -1.92206364e+01,\n",
       "         -1.87656136e+01, -1.74401474e+01, -1.81863136e+01,\n",
       "         -1.79248943e+01, -1.66510220e+01, -1.88593998e+01,\n",
       "         -1.78408356e+01, -1.75672817e+01],\n",
       "        [-1.38281821e-05, -1.13340604e+00, -2.56300066e-02,\n",
       "         -7.34701514e-01, -1.86789739e+00, -4.57976937e-01,\n",
       "         -2.61781700e-02, -1.52825573e-02, -5.82763576e-04,\n",
       "         -2.26748139e-02, -6.04372835e-05, -2.79421368e+01,\n",
       "         -1.91221466e+01, -1.86881580e+01, -1.81536026e+01,\n",
       "         -1.90131302e+01, -1.96214733e+01, -1.76734295e+01,\n",
       "         -1.83524590e+01, -1.90695820e+01, -1.96554184e+01,\n",
       "         -1.97934475e+01, -1.89295330e+01, -1.87432308e+01,\n",
       "         -1.76895733e+01, -1.78219795e+01],\n",
       "        [-9.17907346e-06, -4.79827166e-01, -7.91221738e-01,\n",
       "         -1.65643239e+00, -9.12299156e-02, -3.97629710e-03,\n",
       "         -1.45350921e+00, -6.59608960e-01, -1.67940289e-01,\n",
       "         -2.91950822e-01, -4.08613235e-02, -5.62181510e-02,\n",
       "         -8.47095028e-02, -8.34464686e-07, -2.96322155e+01,\n",
       "         -2.01278915e+01, -1.99364681e+01, -2.01366959e+01,\n",
       "         -2.23506641e+01, -2.09258461e+01, -2.02532635e+01,\n",
       "         -2.23841763e+01, -2.12176037e+01, -2.13677769e+01,\n",
       "         -2.03978672e+01, -1.97921047e+01],\n",
       "        [-1.94309250e-05, -1.88594222e+00, -1.01594098e-01,\n",
       "         -8.91688585e-01, -4.33832929e-02, -4.39183936e-02,\n",
       "         -3.15293998e-01, -1.44791499e-01, -7.70616308e-02,\n",
       "         -1.30969062e-01, -9.37625349e-01, -5.87891899e-02,\n",
       "         -1.68399643e-02, -2.25202739e-02, -3.49277107e-05,\n",
       "         -2.55827160e+01, -1.83842487e+01, -1.80864410e+01,\n",
       "         -1.87110615e+01, -1.76140709e+01, -1.71824379e+01,\n",
       "         -1.78476448e+01, -1.83869724e+01, -1.80337334e+01,\n",
       "         -1.72116146e+01, -1.74663372e+01],\n",
       "        [-8.34461571e-06, -2.36776903e-01, -1.15778737e-01,\n",
       "         -8.51689465e-03, -1.66975334e-02, -3.09943675e-06,\n",
       "         -2.83110466e+01, -1.86879959e+01, -1.81129837e+01,\n",
       "         -1.79566422e+01, -1.78365231e+01, -2.05406475e+01,\n",
       "         -2.11572590e+01, -1.66563396e+01, -1.65057735e+01,\n",
       "         -1.67571545e+01, -1.99333839e+01, -1.99271641e+01,\n",
       "         -1.93387070e+01, -1.81843052e+01, -1.70157242e+01,\n",
       "         -1.67230759e+01, -1.89283810e+01, -1.99136162e+01,\n",
       "         -1.92518520e+01, -1.87375965e+01],\n",
       "        [-1.41858045e-05, -8.25765170e-03, -2.88371239e-02,\n",
       "         -1.93658588e-03, -1.16103110e-04, -8.10950063e-03,\n",
       "         -5.94836674e-05, -2.88314381e+01, -1.92352333e+01,\n",
       "         -1.96383648e+01, -1.99289398e+01, -1.91508160e+01,\n",
       "         -2.05921021e+01, -1.89462261e+01, -1.65536098e+01,\n",
       "         -1.77235661e+01, -1.75128956e+01, -2.00425758e+01,\n",
       "         -1.89475536e+01, -1.78849945e+01, -1.90054131e+01,\n",
       "         -1.77709160e+01, -1.66382179e+01, -1.75985317e+01,\n",
       "         -1.71759033e+01, -1.82439518e+01],\n",
       "        [-1.22784813e-05, -2.02294007e-01, -2.38145053e-01,\n",
       "         -8.19942856e-04, -6.83718687e-03, -2.82823052e-02,\n",
       "         -1.63879290e-01, -9.55319311e-03, -6.66573318e-03,\n",
       "         -3.94385745e-04, -1.51264016e-02, -1.16137753e-03,\n",
       "         -5.15991449e-01, -1.97058339e-02, -4.39189782e-04,\n",
       "         -2.60557572e-04, -2.16753613e-02, -1.38982600e-02,\n",
       "         -2.38418551e-07, -3.04123306e+01, -1.86014156e+01,\n",
       "         -1.91947346e+01, -2.20888367e+01, -2.28584595e+01,\n",
       "         -2.24981689e+01, -2.09450855e+01],\n",
       "        [-2.34839536e-05, -1.27549529e+00, -1.06512858e-02,\n",
       "         -2.88826317e-01, -1.28163188e-03, -8.17831516e-01,\n",
       "         -1.29889473e-01, -5.40237725e-01, -1.34853949e-03,\n",
       "         -1.76452787e-03, -4.27026264e-02, -8.83413851e-02,\n",
       "         -6.51597604e-02, -7.82661214e-02, -1.95722503e-04,\n",
       "         -5.86214840e-01, -2.52930127e-04, -1.95788289e-03,\n",
       "         -2.16369028e-03, -1.16103110e-04, -3.74604628e-04,\n",
       "         -2.50623599e-02, -7.37878290e-05, -5.04719885e-03,\n",
       "         -1.19045051e-02, -1.03587510e-04]], dtype=float32),\n",
       " 'objective/ref_logprobs': array([[-3.69548115e-06, -7.28347540e+00, -2.50382245e-01,\n",
       "         -1.07928782e+01, -5.77823997e-01, -8.49854946e+00,\n",
       "         -1.83081608e+01, -1.87380848e+01, -1.73795433e+01,\n",
       "         -1.77401505e+01, -1.73447838e+01, -1.71657715e+01,\n",
       "         -1.82013683e+01, -1.73401051e+01, -1.64231548e+01,\n",
       "         -1.75704403e+01, -1.69782333e+01, -1.93182659e+01,\n",
       "         -1.85212307e+01, -1.76787987e+01, -1.78760834e+01,\n",
       "         -1.70388374e+01, -1.64796257e+01, -1.74559021e+01,\n",
       "         -1.89510460e+01, -1.86820297e+01],\n",
       "        [-4.17231649e-06, -7.49333286e+00, -4.75335217e+00,\n",
       "         -3.01984131e-01, -3.90334229e-04, -5.51340282e-02,\n",
       "         -8.37891623e-02, -6.81799698e+00, -1.83067226e+01,\n",
       "         -1.75006752e+01, -1.77329330e+01, -1.66179218e+01,\n",
       "         -1.65942249e+01, -1.70600090e+01, -1.65832214e+01,\n",
       "         -1.64748383e+01, -1.67208881e+01, -1.65563316e+01,\n",
       "         -1.69279900e+01, -1.71611423e+01, -1.69430637e+01,\n",
       "         -1.67512894e+01, -1.69453011e+01, -1.69455662e+01,\n",
       "         -1.73079605e+01, -1.77943974e+01],\n",
       "        [-8.46382409e-06, -8.42428398e+00, -7.68531919e-01,\n",
       "         -6.49976015e+00, -2.06731141e-01, -8.54453373e+00,\n",
       "         -1.67760849e+01, -1.64136410e+01, -1.57666817e+01,\n",
       "         -1.55577240e+01, -1.56133614e+01, -1.57065001e+01,\n",
       "         -1.56445274e+01, -1.57575808e+01, -1.56341038e+01,\n",
       "         -1.59644413e+01, -1.58873482e+01, -1.56824684e+01,\n",
       "         -1.54107237e+01, -1.51083746e+01, -1.61128216e+01,\n",
       "         -1.63750153e+01, -1.65277557e+01, -1.61118412e+01,\n",
       "         -1.60919342e+01, -1.60042629e+01],\n",
       "        [-2.38418306e-06, -9.89017105e+00, -2.07301795e-01,\n",
       "         -5.05438831e-04, -5.36383502e-03, -4.19052056e-04,\n",
       "         -5.56657184e-03, -9.01054591e-04, -5.65453582e-02,\n",
       "         -7.17976522e+00, -1.87509556e+01, -1.71051121e+01,\n",
       "         -1.72198830e+01, -1.59050159e+01, -1.60503616e+01,\n",
       "         -1.71699371e+01, -1.68337250e+01, -1.70720921e+01,\n",
       "         -1.61931419e+01, -1.62113743e+01, -1.71323986e+01,\n",
       "         -1.65781250e+01, -1.68728371e+01, -1.65382729e+01,\n",
       "         -1.62209396e+01, -1.68498936e+01],\n",
       "        [-3.93389882e-06, -8.27366066e+00, -5.00779688e-01,\n",
       "         -2.58795440e-01, -7.75020290e-03, -9.63164639e-05,\n",
       "         -1.45305574e-04, -1.18016496e-05, -2.36933655e-03,\n",
       "         -1.32820355e-02, -3.91764188e-04, -2.82599386e-02,\n",
       "         -1.65412158e-01, -1.01709146e+01, -1.78379917e+01,\n",
       "         -1.69959812e+01, -1.69147129e+01, -1.63978176e+01,\n",
       "         -1.63233833e+01, -1.69549046e+01, -1.64609756e+01,\n",
       "         -1.65021725e+01, -1.67363586e+01, -1.74517288e+01,\n",
       "         -1.71593418e+01, -1.63162479e+01],\n",
       "        [-6.67569793e-06, -6.23867607e+00, -6.88077649e-04,\n",
       "         -2.62226065e-04, -1.13332551e-02, -4.05348634e-04,\n",
       "         -1.43926116e-02, -9.10739708e+00, -1.90695076e+01,\n",
       "         -1.79507446e+01, -1.79372749e+01, -1.76128464e+01,\n",
       "         -1.69833660e+01, -1.74965496e+01, -1.66108818e+01,\n",
       "         -1.62777405e+01, -1.72399654e+01, -1.66216774e+01,\n",
       "         -1.72945633e+01, -1.72948971e+01, -1.73873920e+01,\n",
       "         -1.64945812e+01, -1.62123661e+01, -1.69623222e+01,\n",
       "         -1.69392891e+01, -1.73479843e+01],\n",
       "        [-1.06095704e-05, -7.94453669e+00, -2.57768154e-01,\n",
       "         -1.13482296e+00, -1.09541893e+01, -3.58113311e-02,\n",
       "         -1.00911204e-02, -3.97024117e-03, -1.06478423e-01,\n",
       "         -1.81962305e-03, -2.19509308e-03, -3.82537185e-03,\n",
       "         -3.58220816e+00, -4.01960564e+00, -1.99026299e+01,\n",
       "         -2.01900063e+01, -2.07183113e+01, -1.85717468e+01,\n",
       "         -1.83807163e+01, -1.87744923e+01, -1.76937180e+01,\n",
       "         -1.86770077e+01, -1.88261509e+01, -1.85041180e+01,\n",
       "         -1.68515053e+01, -1.99617920e+01],\n",
       "        [-2.86101886e-06, -6.78748846e+00, -3.23084623e-01,\n",
       "         -8.37477112e+00, -1.60213172e+00, -8.17217731e+00,\n",
       "         -1.78905373e+01, -1.72159195e+01, -1.63507500e+01,\n",
       "         -1.62737408e+01, -1.61709709e+01, -1.58321686e+01,\n",
       "         -1.64144955e+01, -1.60414047e+01, -1.57568827e+01,\n",
       "         -1.62761631e+01, -1.62708549e+01, -1.71528168e+01,\n",
       "         -1.67920551e+01, -1.59521904e+01, -1.63076534e+01,\n",
       "         -1.61913242e+01, -1.60729542e+01, -1.61967087e+01,\n",
       "         -1.69024467e+01, -1.69995804e+01],\n",
       "        [-4.17231649e-06, -4.93025541e+00, -4.13741827e+00,\n",
       "         -1.97209045e-01, -7.83406664e-03, -7.12271966e-03,\n",
       "         -7.64519596e+00, -1.75196133e+01, -1.68680096e+01,\n",
       "         -1.66774864e+01, -1.62881603e+01, -1.62256165e+01,\n",
       "         -1.66419144e+01, -1.64634094e+01, -1.61993217e+01,\n",
       "         -1.62461090e+01, -1.61728477e+01, -1.67082272e+01,\n",
       "         -1.62397041e+01, -1.57752361e+01, -1.63215599e+01,\n",
       "         -1.64286499e+01, -1.65256138e+01, -1.71666737e+01,\n",
       "         -1.64623737e+01, -1.60092506e+01],\n",
       "        [-3.33785465e-06, -3.38722038e+00, -9.70380962e-01,\n",
       "         -2.28795362e+00, -2.09469104e+00, -1.28135130e-01,\n",
       "         -3.25507065e-03, -1.73561077e-03, -2.12190280e-05,\n",
       "         -2.22709060e-01, -8.84374809e+00, -1.79653053e+01,\n",
       "         -1.75089359e+01, -1.71080437e+01, -1.63563595e+01,\n",
       "         -1.65514584e+01, -1.70478001e+01, -1.70539131e+01,\n",
       "         -1.74244919e+01, -1.73971062e+01, -1.70911808e+01,\n",
       "         -1.69134865e+01, -1.66323261e+01, -1.71413174e+01,\n",
       "         -1.73494511e+01, -1.76226063e+01],\n",
       "        [-3.57627232e-06, -7.99330616e+00, -7.99737155e-01,\n",
       "         -5.95575905e+00, -2.16400415e-01, -1.14470744e-03,\n",
       "         -2.91222501e+00, -2.72046709e+00, -5.06252468e-01,\n",
       "         -6.34846911e-02, -1.20568371e+00, -3.00208069e-02,\n",
       "         -6.59845769e-02, -7.25909090e+00, -1.79404716e+01,\n",
       "         -1.81899529e+01, -1.86583405e+01, -1.72753716e+01,\n",
       "         -1.77633038e+01, -1.75893688e+01, -1.76056824e+01,\n",
       "         -1.76923275e+01, -1.75697784e+01, -1.72956638e+01,\n",
       "         -1.70319901e+01, -1.67145367e+01],\n",
       "        [-4.52994254e-06, -5.07759285e+00, -3.60937738e+00,\n",
       "         -5.49884021e-01, -1.81120142e-01, -1.08646285e-02,\n",
       "         -2.11634729e-02, -2.71499395e-01, -1.04435310e-01,\n",
       "         -5.81805669e-02, -1.83908319e+00, -2.44263425e-01,\n",
       "         -8.28710422e-02, -4.51182090e-02, -8.35611439e+00,\n",
       "         -1.66393909e+01, -1.66575775e+01, -1.64824905e+01,\n",
       "         -1.62215824e+01, -1.68289299e+01, -1.65098419e+01,\n",
       "         -1.61964798e+01, -1.60790367e+01, -1.58899784e+01,\n",
       "         -1.64120655e+01, -1.65968113e+01],\n",
       "        [-2.02655588e-06, -7.79825640e+00, -1.18511274e-01,\n",
       "         -3.86313489e-03, -5.62235355e-01, -1.04433613e+01,\n",
       "         -1.99615631e+01, -1.80056763e+01, -1.78870049e+01,\n",
       "         -1.74967365e+01, -1.73649101e+01, -1.79498596e+01,\n",
       "         -1.71426086e+01, -1.61992035e+01, -1.63932972e+01,\n",
       "         -1.69161720e+01, -1.77502937e+01, -1.73966179e+01,\n",
       "         -1.65129967e+01, -1.62773838e+01, -1.62245636e+01,\n",
       "         -1.63014030e+01, -1.72645493e+01, -1.70930481e+01,\n",
       "         -1.66306229e+01, -1.70908527e+01],\n",
       "        [-3.09943675e-06, -6.89010429e+00, -4.44783688e-01,\n",
       "         -1.03448145e-02, -1.53053328e-02, -6.05587587e-02,\n",
       "         -4.05833197e+00, -1.89159184e+01, -1.74617748e+01,\n",
       "         -1.75191765e+01, -1.57628012e+01, -1.57038965e+01,\n",
       "         -1.61305103e+01, -1.58546371e+01, -1.57018156e+01,\n",
       "         -1.59789877e+01, -1.60791512e+01, -1.61892681e+01,\n",
       "         -1.70934334e+01, -1.71068516e+01, -1.59159784e+01,\n",
       "         -1.56486025e+01, -1.58965435e+01, -1.59840260e+01,\n",
       "         -1.61640720e+01, -1.67183876e+01],\n",
       "        [-4.41073416e-06, -8.87938690e+00, -6.01200759e-01,\n",
       "         -3.73380817e-03, -5.55958152e-01, -1.02323554e-01,\n",
       "         -8.97015259e-02, -3.34537122e-03, -3.10367998e-03,\n",
       "         -1.23400812e-03, -2.51596305e-03, -2.74620485e-04,\n",
       "         -1.77286953e-01, -1.65099627e-03, -1.62707444e-03,\n",
       "         -1.87156838e-05, -5.20458072e-03, -4.00799885e-03,\n",
       "         -9.28597808e-01, -1.74981785e+01, -1.77097931e+01,\n",
       "         -1.79220943e+01, -1.73450985e+01, -1.75106812e+01,\n",
       "         -1.72534485e+01, -1.75235825e+01],\n",
       "        [-7.98699057e-06, -9.01490307e+00, -1.56059265e-01,\n",
       "         -1.18276596e-01, -5.12171090e-02, -9.51496884e-02,\n",
       "         -1.81284338e-01, -2.19818488e-01, -6.53724233e-03,\n",
       "         -3.69361369e-04, -1.87587187e-01, -1.98405725e-03,\n",
       "         -8.36866256e-03, -5.02798427e-03, -2.69376702e-04,\n",
       "         -1.71400509e+01, -1.72049727e-03, -9.26303852e-04,\n",
       "         -1.05623237e-03, -2.67025243e-05, -5.72188219e-05,\n",
       "         -3.10245529e-02, -2.33503728e-04, -6.42331725e-04,\n",
       "         -6.72055921e-03, -4.90093422e+00]], dtype=float32),\n",
       " 'objective/kl_coef': 0.20277051228632129,\n",
       " 'objective/entropy': 2.1606876850128174,\n",
       " 'ppo/mean_non_score_reward': -0.3793238699436188,\n",
       " 'ppo/mean_scores': 0.47543710470199585,\n",
       " 'ppo/std_scores': 0.005793577991425991,\n",
       " 'tokens/queries_len_mean': 374.875,\n",
       " 'tokens/queries_len_std': 83.20806884765625,\n",
       " 'tokens/queries_dist': array([479., 507., 504., 339., 374., 298., 415., 266., 272., 470., 277.,\n",
       "        294., 410., 388., 358., 347.], dtype=float32),\n",
       " 'tokens/responses_len_mean': 12.0625,\n",
       " 'tokens/responses_len_std': 5.674137115478516,\n",
       " 'tokens/responses_dist': array([ 7.,  9.,  7., 11., 15.,  9., 15.,  7.,  8., 12., 15., 16.,  7.,\n",
       "         8., 20., 27.], dtype=float32),\n",
       " 'ppo/loss/policy': -0.059072017669677734,\n",
       " 'ppo/loss/value': 0.2863040566444397,\n",
       " 'ppo/loss/total': -0.030441604554653168,\n",
       " 'ppo/policy/entropy': 0.49586543440818787,\n",
       " 'ppo/policy/approxkl': 0.364953875541687,\n",
       " 'ppo/policy/policykl': 0.09842631220817566,\n",
       " 'ppo/policy/clipfrac': 0.127714604139328,\n",
       " 'ppo/policy/advantages': array([-5.026945  ,  0.36142185,  0.6208201 , ..., -0.04596541,\n",
       "        -0.04596541, -0.04596541], dtype=float32),\n",
       " 'ppo/policy/advantages_mean': 0.027625955641269684,\n",
       " 'ppo/policy/ratio': array([1.       , 1.       , 1.       , ..., 2.116677 , 1.9945686,\n",
       "        2.0834835], dtype=float32),\n",
       " 'ppo/returns/mean': -1.6166677474975586,\n",
       " 'ppo/returns/var': 1.2006113529205322,\n",
       " 'ppo/val/vpred': -1.618414282798767,\n",
       " 'ppo/val/error': 0.5644440054893494,\n",
       " 'ppo/val/clipfrac': 0.04546498507261276,\n",
       " 'ppo/val/mean': -1.6762802600860596,\n",
       " 'ppo/val/var': 0.9277287721633911,\n",
       " 'ppo/val/var_explained': 0.5298694968223572,\n",
       " 'ppo/learning_rate': 1.41e-05,\n",
       " 'time/ppo/forward_pass': 2.7115604877471924,\n",
       " 'time/ppo/compute_rewards': 0.002160787582397461,\n",
       " 'time/ppo/compute_advantages': 0.0020372867584228516,\n",
       " 'time/ppo/optimize_step': 14.327406406402588,\n",
       " 'time/ppo/calc_stats': 0.9457166194915771,\n",
       " 'time/ppo/total': 17.988965034484863}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "256c3ba8-c9be-45b9-8779-ed986499aed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoModelForSeq2SeqLMWithValueHead(\n",
       "  (pretrained_model): LEDForConditionalGeneration(\n",
       "    (led): LEDModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): LEDEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LEDLearnedPositionalEmbedding(16384, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x LEDEncoderLayer(\n",
       "            (self_attn): LEDEncoderAttention(\n",
       "              (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): LEDDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LEDLearnedPositionalEmbedding(1024, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x LEDDecoderLayer(\n",
       "            (self_attn): LEDDecoderAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): LEDDecoderAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8d5a26f-98f5-4608-913f-c7fbb695b6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 1024, 'min_length': 8, 'early_stopping': True, 'num_beams': 4, 'repetition_penalty': 3.5, 'length_penalty': 0.8, 'no_repeat_ngram_size': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('ppo_model_tokenizer_final_new/tokenizer_config.json',\n",
       " 'ppo_model_tokenizer_final_new/special_tokens_map.json',\n",
       " 'ppo_model_tokenizer_final_new/vocab.json',\n",
       " 'ppo_model_tokenizer_final_new/merges.txt',\n",
       " 'ppo_model_tokenizer_final_new/added_tokens.json',\n",
       " 'ppo_model_tokenizer_final_new/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_model_path = \"ppo_model_final_new\"\n",
    "ppo_model_tokenizer = \"ppo_model_tokenizer_final_new\"\n",
    "\n",
    "# ppo_trainer.save_model(\"ppo_model_path\")\n",
    "# Save the model\n",
    "ppo_model.save_pretrained(ppo_model_path)\n",
    "\n",
    "# Save the tokenizer\n",
    "policy_tokenizer.save_pretrained(ppo_model_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7392aca0-e4a1-4533-8ca5-1dec128016fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ppo_model_final_new were not used when initializing LEDForConditionalGeneration: ['v_head.summary.bias', 'v_head.summary.weight']\n",
      "- This IS expected if you are initializing LEDForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEDForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# ppo_saved_model_path = \"ppo_model_20Epochs_new\"\n",
    "# tokenizer_path = \"ppo_model_tokenizer_new\"\n",
    "ppo_model = AutoModelForSeq2SeqLM.from_pretrained(ppo_model_path)\n",
    "policy_tokenizer = AutoTokenizer.from_pretrained(ppo_model_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02cfed83-8cfe-4f1a-9425-9f6b28544c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_summary(prompt: str, model, tokenizer, generation_kwargs, output_length_sampler) -> str:\n",
    "#     \"\"\"\n",
    "#     Generate a summary for a given prompt using a trained policy model.\n",
    "\n",
    "#     Args:\n",
    "#     - prompt (str): The input text for which a summary needs to be generated.\n",
    "#     - model: The trained policy model.\n",
    "#     - tokenizer: The tokenizer used for the policy model.\n",
    "#     - generation_kwargs (dict): Arguments used for response generation.\n",
    "#     - output_length_sampler (func): Function to sample the length of the output.\n",
    "\n",
    "#     Returns:\n",
    "#     - str: Generated summary.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Tokenize the prompt\n",
    "#     prompt_tensor = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "#     # Ensure it's only one tensor and check its shape\n",
    "#     assert prompt_tensor.dim() == 2, f\"Unexpected tensor shape: {prompt_tensor.shape}\"\n",
    "\n",
    "#     # Set the generation arguments\n",
    "#     max_new_tokens = output_length_sampler()\n",
    "#     generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "\n",
    "#     # Generate a summary\n",
    "#     summary_tensor = model.generate(input_ids=prompt_tensor, **generation_kwargs)\n",
    "\n",
    "#     # Decode and return the summary\n",
    "#     summary = tokenizer.decode(summary_tensor[0], skip_special_tokens=True)\n",
    "#     return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6524c541-814c-485a-887b-f5858754d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/AskReddit\\nTITLE: I need your hel...</td>\n",
       "      <td>American Family Insurance is screwing me with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/relationships\\nTITLE: My boyfrien...</td>\n",
       "      <td>Boyfriend of 3 years started a business withou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/AskReddit\\nTITLE: Can someone hel...</td>\n",
       "      <td>Grandpa had a light bulb he could light up by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/travel\\nTITLE: If I don't do this...</td>\n",
       "      <td>I'm an American, bored with my career, wanting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/tifu\\nTITLE: TIFU By Showing My H...</td>\n",
       "      <td>Made a bet with teacher to watch Vader vs Hitl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUBREDDIT: r/dating_advice\\nTITLE: Should I [1...</td>\n",
       "      <td>Have a bit of a crush on a guy who I see every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUBREDDIT: r/relationship_advice\\nTITLE: When ...</td>\n",
       "      <td>If we both know we like each other, and have r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ha...</td>\n",
       "      <td>Interested in a girl i sit with next to in cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUBREDDIT: r/Advice\\nTITLE: Freaking out about...</td>\n",
       "      <td>Freaking out about college being too much and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUBREDDIT: r/personalfinance\\nTITLE: 25 y/o lo...</td>\n",
       "      <td>forces out of home. I have $400 and $6000 debt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  SUBREDDIT: r/AskReddit\\nTITLE: I need your hel...   \n",
       "1  SUBREDDIT: r/relationships\\nTITLE: My boyfrien...   \n",
       "2  SUBREDDIT: r/AskReddit\\nTITLE: Can someone hel...   \n",
       "3  SUBREDDIT: r/travel\\nTITLE: If I don't do this...   \n",
       "4  SUBREDDIT: r/tifu\\nTITLE: TIFU By Showing My H...   \n",
       "5  SUBREDDIT: r/dating_advice\\nTITLE: Should I [1...   \n",
       "6  SUBREDDIT: r/relationship_advice\\nTITLE: When ...   \n",
       "7  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ha...   \n",
       "8  SUBREDDIT: r/Advice\\nTITLE: Freaking out about...   \n",
       "9  SUBREDDIT: r/personalfinance\\nTITLE: 25 y/o lo...   \n",
       "\n",
       "                                               label  \n",
       "0  American Family Insurance is screwing me with ...  \n",
       "1  Boyfriend of 3 years started a business withou...  \n",
       "2  Grandpa had a light bulb he could light up by ...  \n",
       "3  I'm an American, bored with my career, wanting...  \n",
       "4  Made a bet with teacher to watch Vader vs Hitl...  \n",
       "5  Have a bit of a crush on a guy who I see every...  \n",
       "6  If we both know we like each other, and have r...  \n",
       "7  Interested in a girl i sit with next to in cla...  \n",
       "8  Freaking out about college being too much and ...  \n",
       "9  forces out of home. I have $400 and $6000 debt...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_sample = pd.read_csv('testing_samples.csv')\n",
    "testing_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "928d5f31-c241-43a0-96eb-3601319af7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=policy_model, tokenizer=policy_tokenizer) #max_length=350, num_return_sequences=1\n",
    "Base_model_summary = []\n",
    "for i in testing_sample['prompt']:\n",
    "    output = pipe(i,temperature =  1.0, min_length = 5, top_k = 0.0, top_p = 1.0, do_sample =  True, max_length=150)\n",
    "    Base_model_summary.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25e3d29a-f570-4598-bbca-42d5b3df1e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': 'A Redditch is asking Reddit for help finding his insurance company, American Family Insurance. He explains that he was involved in a car accident where the other driver was at fault. The insurance company arranged for him to get a rental car and pay for auto body repair at the shop my dealer recommended. However, when he picked up the rental car, the insurance company paid for it, he had to sign for the coverage that the rental company (Enterprise) offers, which is $13 a day. This means that he will have to buy a new car every 2 weeks. Plus, there\\'s no way this insurance company can \"pay for rental insurance when their client is at fault.\" Translation: I don\\'t have full liability insurance, so'}],\n",
       " [{'summary_text': 'A Reddit user has been asking a question about relationships: Why is it that his \"part-time grad student\" boyfriend of 3 years keeps making huge decisions without communicating with me [23 F] at all, is this normal? The redditor explains that he\\'s just trying to figure out what the heck is going on.'}],\n",
       " [{'summary_text': 'AskReddit: r/AskReddit This is about a lightbulb that my dad used to bring home from work. When my dad was growing up, his dad would bring them different little toys and other things he would bring with him. When the kids were younger, their dad would sometimes put this thing in their mouth and somehow light it up. The kids still have no idea how it worked. If anyone knows where I can find one of these, if they exist still, or how they work? Thanks!SUBREDDIT: /AskReddit Post: Originally posted on AskReddit . A redditor named Pete asks for someone to help him find a \"lightbulb\" that his dad grew up using. His dad died 15'}],\n",
       " [{'summary_text': 'A Redditor has a question about how to \"reboot\" his life if he doesn\\'t start working right away. He\\'s an American studying in Australia with a specific career goal; he wants to sell all of his possessions, put the rest in storage, and move to Australia for a year on a 1 year visa. He needs some advice on making a major life decision. He says this because he hasn\\'t had much time to make a big decision yet - he just doesn\\'t have much time left to do it. The redditor also suggests that maybe he can \"start a change\" by \"mending his batteries \"find myself\" and be done with it sooner than expected\" . His name is Mr. Post, and he'}],\n",
       " [{'summary_text': \"A Redditch has been following a student's progress in his class, Tifu. He is doing year 11 history and he won a bet with his teacher that if our document analysis (an essay thingy) impressed him first time, they get to watch season 1-3 of ERB of History, Vader vs Hitler ofc, cause we're studying the Nazis...Well, I impressed, mainly cause I'm repeating the unit (by choice, I did it a year early and wanted more practice before doing year 12 history) and remembered how to write these really well. The class thinks Im some dork whos obsessed with nerdy youtube now, teacher said hes never making a bet again, Every bloody person shakes their head at\"}],\n",
       " [{'summary_text': 'A Redditor who has a friend\\'s sister ask her to prom. She says yes, but only as friends. The guy she\\'s hanging out with is awkward and \"very very platonic,\" according to the Redditor. He goes on a few dead-end dates with his friend\\'s sis, who doesn\\'t seem to have any feelings for him at all. The weirdest thing is that he asks her to go on some really lame dates with him. It turns out they\\'re actually going to hang out together, which sucks because they haven\\'t even hung out in a month. The Redditor then decides to give the guy his phone number so he can figure out if there\\'s anything going on between them. Uh-oh.'}],\n",
       " [{'summary_text': 'A Redditor has asked a girl on a social media platform if it\\'s okay to ask her to be \"my girlfriend\" because she\\'s been hanging out with her after school a lot and got to know each other. The redditor, Post, is wondering if it would be ok to just straight up ask/be \"more than friends\"? It sounds like a great idea, right?'}],\n",
       " [{'summary_text': \"SUBREDDIT: I [18 M] have been talking to [18 F] in my class. We do a quick conversation but don't talk much after. I'm also interested in asking her out but not sure how to go with that. Also, she's homeschooled so maybe she doesn't know how to converse either? This professor is weird and had us both assigned seats. So they usually just say simple things and actions but it just stops soon. And sometimes we just didn't say anything to each other. Hmm... Maybe I should start bringing my self in?\"}],\n",
       " [{'summary_text': 'This is a really confusing post from a 19-year old pre-med student at a public university. He\\'s studying Organic Chemistry 1 + Lab and Bio 2 + Lab, but he\\'s not doing very well in both classes. His grades just got worse and worse. He doesn\\'t have any other interests besides to become a pediatrician. This totally sucks. The dude also has an ulterior motive: he wants to be a doctor. You know, the whole \"I don\\'t even compare to anybody else with a 3.3 GPA and not getting A\\'s in every science class I\\'ve taken\" thing. In case you haven\\'t figured it out yet, this guy is freaking out about his college life. And if you\\'re wondering'}],\n",
       " [{'summary_text': 'A 25-year-old man named Post is r/personalfinance. He\\'s 26 years old and has lost the love and support of his family and friends due to personal circumstances. He says he needs to move and start over, but that he currently has only $400 in the bank and roughly $6000 in debt. He also has a job offer for a large corporate company in sales. They really want me. They claim there sales people make 3-5 sales a week with a $450 commission per sale. This is great money for me, but it\\'s commission so it\\'s not guaranteed that I\\'ll make those sales. Post explains that he doesn\\'t have enough money to go on a trip, so he decides to \"'}]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base_model_summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2969f1fd-33d6-4526-b7ad-c3bd3fc92c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'AutoModelForSeq2SeqLMWithValueHead' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': 'Does my car need repair?'}],\n",
       " [{'summary_text': 'Does this normal?'}],\n",
       " [{'summary_text': 'Can someone please help my dad?'}],\n",
       " [{'summary_text': \"I'm looking for advice, help, reassurance, dissuasion or a little bit of each on a major life decision.\"}],\n",
       " [{'summary_text': 'Why would you need those movies?'}],\n",
       " [{'summary_text': \"Should I, who went on a couple dead end dates with my friend's sister?\"}],\n",
       " [{'summary_text': 'Does it alright to just ask here to be \"more than friends\"?'}],\n",
       " [{'summary_text': 'I am talking to a student in my class.'}],\n",
       " [{'summary_text': 'What do I do?'}],\n",
       " [{'summary_text': 'Does a career change make a smart idea?'}]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=ppo_model, tokenizer=policy_tokenizer) #max_length=350, num_return_sequences=1\n",
    "PPO_model_summary = []\n",
    "for i in testing_sample['prompt']:\n",
    "    output = pipe(i,temperature =  1.0, min_length = 5, top_k = 0.0, top_p = 1.0, do_sample = True, max_length=150)\n",
    "    PPO_model_summary.append(output)\n",
    "PPO_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d70ed755-c01f-49d9-9029-5bfe787b5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sample['base_model'] = Base_model_summary\n",
    "testing_sample['PPO'] = PPO_model_summary\n",
    "\n",
    "rlhf_result = testing_sample\n",
    "\n",
    "rlhf_result.to_csv('rlhf_result_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6932f0b-bbf8-4d0a-9d0f-f7ea8752cfe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m testing_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarize: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m i\n\u001b[0;32m----> 4\u001b[0m     generated_summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_length_sampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     Base_model_summary\u001b[38;5;241m.\u001b[39mappend(generated_summary)\n",
      "Cell \u001b[0;32mIn[71], line 27\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[0;34m(prompt, model, tokenizer, generation_kwargs, output_length_sampler)\u001b[0m\n\u001b[1;32m     24\u001b[0m generation_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_new_tokens\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Generate a summary\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m summary_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Decode and return the summary\u001b[39;00m\n\u001b[1;32m     30\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_tensor[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1370\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m         )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:491\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    489\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    490\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 491\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/led/modeling_led.py:1799\u001b[0m, in \u001b[0;36mLEDEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1799\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;66;03m# create default attention_mask\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# Base_model_summary = []\n",
    "# for i in testing_sample['prompt']:\n",
    "#     prompt = \"summarize: \" + i\n",
    "#     generated_summary = generate_summary(prompt, policy_model, policy_tokenizer, generation_kwargs, output_length_sampler)\n",
    "#     Base_model_summary.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11a0efb2-a5b8-4abb-a163-8287e369555d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m testing_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarize: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m i\n\u001b[0;32m----> 4\u001b[0m     generated_summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_length_sampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     ppo_model_summary\u001b[38;5;241m.\u001b[39mappend(generated_summary)\n",
      "Cell \u001b[0;32mIn[75], line 27\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[0;34m(prompt, model, tokenizer, generation_kwargs, output_length_sampler)\u001b[0m\n\u001b[1;32m     24\u001b[0m generation_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_new_tokens\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Generate a summary\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m summary_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Decode and return the summary\u001b[39;00m\n\u001b[1;32m     30\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_tensor[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/trl/models/modeling_value_head.py:431\u001b[0m, in \u001b[0;36mAutoModelForSeq2SeqLMWithValueHead.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    We call `generate` on the wrapped model.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1370\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m         )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:491\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    489\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    490\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 491\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/led/modeling_led.py:1799\u001b[0m, in \u001b[0;36mLEDEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1799\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;66;03m# create default attention_mask\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# ppo_model_summary = []\n",
    "# for i in testing_sample['prompt']:\n",
    "#     prompt = \"summarize: \" + i\n",
    "#     generated_summary = generate_summary(prompt, ppo_model, policy_tokenizer, generation_kwargs, output_length_sampler)\n",
    "#     ppo_model_summary.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f7d1c72f-05df-45a3-b3ba-59836f9acee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = pipeline(\"summarization\", model=ppo_model, tokenizer=policy_tokenizer) #max_length=350, num_return_sequences=1\n",
    "# PPO_model_summary = []\n",
    "# for i in testing_sample['prompt']:\n",
    "#     output = pipe(i,temperature =  1.0, min_length = 5, top_k = 0.0, top_p = 1.0, do_sample =  True, max_length=150)\n",
    "#     PPO_model_summary.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ce389b0d-0a26-48d5-9efd-bf4d1f841b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': 'Oh, yeah.'}],\n",
       " [{'summary_text': 'Oh, yeah.'}],\n",
       " [{'summary_text': 'Oh, yeah.'}],\n",
       " [{'summary_text': 'Oh yeah.'}],\n",
       " [{'summary_text': 'Oh, yeah'}],\n",
       " [{'summary_text': 'Oh, yeah.'}],\n",
       " [{'summary_text': 'Oh, yeah.'}],\n",
       " [{'summary_text': 'Oh yeah.'}],\n",
       " [{'summary_text': 'Oh, yeah.'}],\n",
       " [{'summary_text': 'Oh, yeah.'}]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PPO_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997da30-7f65-4546-9414-f108cc16ffee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

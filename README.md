# RLHF_vs_DPO
Did a Comparative study between RLHF vs DPO on a Summary Dataset from HuggingFace.....Trained a Reward Model using TRL's Reward Trainer, leveraged bert-base-uncased as Reward Model, for PPO and DPO training leveraged a finetuned Summary Model. PPO using PPOTrainer and DPO using DPOTrainer.
DPO outperforms PPO in case of effective summary generation.
